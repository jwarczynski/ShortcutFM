{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cosine Similarity Analysis of Model Predictions During Denoising\n",
    "\n",
    "This notebook analyzes the cosine similarity between model predictions and ground truth velocities during the denoising process. We'll:\n",
    "\n",
    "1. Load a trained model from a checkpoint\n",
    "2. Perform denoising for a single example and track velocities\n",
    "3. Calculate cosine similarities between model predictions and ground truth velocities\n",
    "4. Visualize the results\n",
    "5. Extend the analysis to multiple examples and compute statistics\n",
    "6. Visualize top-k tokens for each denoising step with probabilities and L2 distances"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "# Add parent directory to path to import shortcutfm modules\n",
    "sys.path.append('..')\n",
    "\n",
    "from shortcutfm.batch import collate\n",
    "from shortcutfm.config import TrainingConfig\n",
    "from shortcutfm.text_datasets import TextDataset\n",
    "from shortcutfm.train.pl.trainer_factory import (\n",
    "    create_criterion,\n",
    "    load_unit_from_checkpoint,\n",
    ")\n",
    "from shortcutfm.analysis.token_analysis import (\n",
    "    analyze_token_predictions,\n",
    "    denoise_with_token_tracking,\n",
    "    visualize_top_k_tokens,\n",
    ")\n",
    "from typing import Any\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load Configuration and Model\n",
    "\n",
    "First, we'll load the training configuration from a checkpoint directory and initialize the model."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set the checkpoint directory\n",
    "checkpoint_dir = Path(\"../checkpoints/run_q2qzjeso\")\n",
    "checkpoint_path = checkpoint_dir / \"epoch=190-step=27100.ckpt\"\n",
    "training_config_path = checkpoint_dir / \"training_config.yaml\"\n",
    "\n",
    "# Load training configuration\n",
    "with open(training_config_path) as f:\n",
    "    yaml_cfg = OmegaConf.load(f)\n",
    "\n",
    "training_config = TrainingConfig(**OmegaConf.to_container(yaml_cfg, resolve=True))\n",
    "print(f\"Loaded training config from {training_config_path}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set random seed for reproducibility\n",
    "pl.seed_everything(training_config.seed)\n",
    "\n",
    "# Create criterion and load model from checkpoint\n",
    "criterion = create_criterion(training_config)\n",
    "unit = load_unit_from_checkpoint(criterion, checkpoint_path, training_config)\n",
    "print(f\"Loaded model from {checkpoint_path}\")\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "unit.eval()\n",
    "print(\"UNIT lodaed succesfully\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tokenizer = unit.criterion.flow_matching_criterion.tokenizer\n",
    "\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "# Filter unused tokens\n",
    "unused_tokens = [token for token in vocab.keys() if token.startswith('[unused')]\n",
    "\n",
    "# Print unused tokens and their corresponding IDs\n",
    "for token in unused_tokens:\n",
    "    print(f\"Token: {token}, ID: {vocab[token]}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('answerdotai/ModernBERT-base')\n",
    "\n",
    "# Get the vocabulary\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "# Filter unused tokens\n",
    "unused_tokens = [token for token in vocab.keys() if token.startswith('[unused')]\n",
    "\n",
    "# Print unused tokens and their corresponding IDs\n",
    "for token in unused_tokens:\n",
    "    print(f\"Token: {token}, ID: {vocab[token]}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "embedding = torch.nn.Embedding(10, 768)\n",
    "matrix = embedding.weight.data\n",
    "matrix.dtype"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load Test Data\n",
    "\n",
    "Now we'll load some test data to use for our analysis."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load test dataset\n",
    "from shortcutfm.batch import EncoderBatch\n",
    "\n",
    "\n",
    "test_data_path = \"../datasets/tokenized/bert-base-uncased/QQP-Official/test\"\n",
    "test_ds = Dataset.load_from_disk(test_data_path)\n",
    "test_text_ds = TextDataset(test_ds)\n",
    "\n",
    "# Create a small batch for analysis\n",
    "batch_size = 8\n",
    "test_dataloader = DataLoader(\n",
    "    test_text_ds,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Get a single batch for analysis\n",
    "test_batch: EncoderBatch = next(iter(test_dataloader))\n",
    "print(f\"Loaded test batch with {len(test_batch.seqs)} examples\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Single Example Analysis\n",
    "\n",
    "Let's analyze the denoising process for a single example."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set shortcut size for denoising\n",
    "from shortcutfm.analysis.velocity_analysis import denoise_with_tracking\n",
    "\n",
    "\n",
    "shortcut_size = 64\n",
    "\n",
    "# Run denoising with tracking\n",
    "results = denoise_with_tracking(unit, test_batch, shortcut_size, per_token_cosine=True)\n",
    "\n",
    "# Extract results\n",
    "timesteps = results[\"timesteps\"]\n",
    "cosine_similarities = [cs.cpu().numpy() for cs in results[\"cosine_similarities\"]]\n",
    "\n",
    "# Convert to numpy for easier plotting\n",
    "cosine_similarities_np = np.array([cs.mean().item() for cs in cosine_similarities])\n",
    "\n",
    "print(f\"Analyzed denoising process with {len(timesteps)} steps\")\n",
    "cosine_similarities\n",
    "# results"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compare per-token vs flattened cosine similarity calculations and plot with L2 distances\n",
    "results_per_token = denoise_with_tracking(unit, test_batch, 4, per_token_cosine=True)\n",
    "# results_flattened = denoise_with_tracking(unit, test_batch, 4, per_token_cosine=False)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Extract results\n",
    "timesteps = results_per_token[\"timesteps\"]\n",
    "cosine_similarities_per_token = [cs.cpu().numpy().mean() for cs in results_per_token[\"cosine_similarities\"]]\n",
    "# cosine_similarities_flattened = [cs.cpu().numpy().mean() for cs in results_flattened[\"cosine_similarities\"]]\n",
    "l2_distances = results_per_token[\"l2_distances\"]\n",
    "velocity_l2_distances = results_per_token[\"velocity_l2_distances\"]\n",
    "predicted_velocity_norms = results_per_token[\"predicted_velocity_norms\"] \n",
    "ground_truth_velocity_norms = results_per_token[\"ground_truth_velocity_norms\"]\n",
    "\n",
    "# Create two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "# First subplot - Cosine similarities and L2 distances\n",
    "ax1.plot(timesteps, cosine_similarities_per_token, marker='o', linestyle='-', linewidth=2, color='blue', label='Per-token Cosine')\n",
    "# ax1.plot(timesteps, cosine_similarities_flattened, marker='s', linestyle='--', linewidth=2, color='green', label='Flattened Cosine')\n",
    "ax1.set_xlabel('Timestep')\n",
    "ax1.set_ylabel('Cosine Similarity', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.set_ylim(-1.1, 1.1)\n",
    "ax1.grid(True)\n",
    "\n",
    "# Create twin axis for L2 distances\n",
    "ax1_twin = ax1.twinx()\n",
    "ax1_twin.plot(timesteps, l2_distances, marker='^', linestyle=':', linewidth=2, color='red', label='L2 Distance')\n",
    "ax1_twin.set_ylabel('L2 Distance', color='red')\n",
    "ax1_twin.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Add title and legend for first subplot\n",
    "ax1.set_title('Cosine Similarities and L2 Distance')\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax1_twin.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "\n",
    "# Second subplot - Velocity L2 distances and norms\n",
    "ax2.plot(timesteps, velocity_l2_distances, marker='o', linestyle='-', linewidth=2, color='purple', label='Velocity L2 Distance')\n",
    "ax2.set_xlabel('Timestep')\n",
    "ax2.set_ylabel('Velocity L2 Distance', color='purple')\n",
    "ax2.tick_params(axis='y', labelcolor='purple')\n",
    "ax2.grid(True)\n",
    "\n",
    "# Create twin axis for velocity norms\n",
    "ax2_twin = ax2.twinx()\n",
    "ax2_twin.plot(timesteps, predicted_velocity_norms, marker='s', linestyle='--', linewidth=2, color='orange', label='Predicted Velocity Norm')\n",
    "ax2_twin.plot(timesteps, ground_truth_velocity_norms, marker='^', linestyle=':', linewidth=2, color='brown', label='Ground Truth Velocity Norm')\n",
    "ax2_twin.set_ylabel('Velocity Norm', color='orange')\n",
    "ax2_twin.tick_params(axis='y', labelcolor='orange')\n",
    "\n",
    "# Add title and legend for second subplot\n",
    "ax2.set_title('Velocity L2 Distance and Norms')\n",
    "lines3, labels3 = ax2.get_legend_handles_labels()\n",
    "lines4, labels4 = ax2_twin.get_legend_handles_labels()\n",
    "ax2.legend(lines3 + lines4, labels3 + labels4, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_noise_to_target_distance(\n",
    "    target_embeddings: Tensor,\n",
    "    input_mask: Tensor,\n",
    "    padding_mask: Tensor,\n",
    "    num_samples: int = 100,\n",
    ") -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate L2 distance and velocity norm between random noise and target embeddings.\n",
    "\n",
    "    Args:\n",
    "        target_embeddings: Target embeddings [batch_size, seq_len, hidden_dim]\n",
    "        input_mask: Mask indicating input positions (0 for input, 1 for target) [batch_size, seq_len, 1]\n",
    "        padding_mask: Mask indicating padding (0 for padding, 1 for actual tokens) [batch_size, seq_len, 1]\n",
    "        num_samples: Number of random noise samples to generate\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "        - mean_distance: Mean L2 distance across all samples\n",
    "        - std_distance: Standard deviation of L2 distances\n",
    "        - min_distance: Minimum L2 distance observed\n",
    "        - max_distance: Maximum L2 distance observed\n",
    "    \"\"\"\n",
    "    distances = []\n",
    "    valid_token_mask = input_mask.squeeze(-1).bool() & padding_mask.bool()\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # Generate random noise with same shape as target embeddings\n",
    "        noise = torch.randn_like(target_embeddings)\n",
    "        \n",
    "        # Calculate L2 distances only for valid tokens\n",
    "        l2_dists = torch.norm(\n",
    "            noise[valid_token_mask] - target_embeddings[valid_token_mask],\n",
    "            dim=-1\n",
    "        )  # [num_valid_tokens]\n",
    "        \n",
    "        # Average L2 distance and velocity norm across valid tokens\n",
    "        mean_dist = l2_dists.mean().item()\n",
    "        distances.append(mean_dist)\n",
    "\n",
    "    distances = torch.tensor(distances)\n",
    "    \n",
    "    return {\n",
    "        \"mean_distance\": distances.mean().item(),\n",
    "        \"std_distance\": distances.std().item(),\n",
    "        \"min_distance\": distances.min().item(),\n",
    "        \"max_distance\": distances.max().item(),\n",
    "    }"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Example usage\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "target_embeddings = unit.criterion.model.get_embeddings(test_batch.seqs.to(device))\n",
    "distances = calculate_noise_to_target_distance(\n",
    "    target_embeddings=target_embeddings,\n",
    "    input_mask=test_batch.input_ids_mask,\n",
    "    padding_mask=test_batch.padding_mask,\n",
    "    num_samples=100  # Generate 100 random noise samples\n",
    ")\n",
    "\n",
    "print(f\"Mean L2 distance: {distances['mean_distance']:.4f}\")\n",
    "print(f\"Std L2 distance: {distances['std_distance']:.4f}\")\n",
    "print(f\"Min L2 distance: {distances['min_distance']:.4f}\")\n",
    "print(f\"Max L2 distance: {distances['max_distance']:.4f}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualize top-k tokens for each denoising step\n",
    "print(\"\\nVisualizing top-k tokens for each denoising step...\")\n",
    "token_results = denoise_with_token_tracking(unit, test_batch, shortcut_size, top_k=5)\n",
    "\n",
    "# Select a few representative timesteps to visualize\n",
    "timesteps = token_results[\"timesteps\"]\n",
    "num_steps = len(timesteps)\n",
    "\n",
    "# Choose timesteps at different points in the denoising process\n",
    "timestep_indices = [0, num_steps // 4, num_steps // 2, 3 * num_steps // 4, num_steps - 1]\n",
    "\n",
    "# Visualize the selected timesteps\n",
    "visualize_top_k_tokens(token_results, timestep_indices=timestep_indices)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Individual Example Analysis\n",
    "\n",
    "Let's look at the cosine similarities for each example in the batch."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Batch Analysis\n",
    "\n",
    "Now let's analyze multiple batches to get more robust statistics."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def analyze_multiple_batches(model, dataloader, shortcut_size, num_batches=5):\n",
    "    \"\"\"\n",
    "    Analyze cosine similarities across multiple batches.\n",
    "    \n",
    "    Args:\n",
    "        model: The model to use for denoising\n",
    "        dataloader: DataLoader providing batches\n",
    "        shortcut_size: Shortcut size for denoising\n",
    "        num_batches: Number of batches to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with aggregated statistics\n",
    "    \"\"\"\n",
    "    all_cosine_sims = []\n",
    "    timesteps = None\n",
    "\n",
    "    # Process multiple batches\n",
    "    dataloader_iter = iter(dataloader)\n",
    "    for i in tqdm(range(num_batches), desc=\"Processing batches\"):\n",
    "        try:\n",
    "            batch = next(dataloader_iter)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "        # Run denoising with tracking\n",
    "        results = denoise_with_tracking(model, batch, shortcut_size, per_token_cosine=True)\n",
    "\n",
    "        # Store timesteps from first batch\n",
    "        if timesteps is None:\n",
    "            timesteps = results[\"timesteps\"]\n",
    "\n",
    "        # Extract and store cosine similarities\n",
    "        batch_cos_sims = [cs.cpu().numpy() for cs in results[\"cosine_similarities\"]]\n",
    "        all_cosine_sims.append(batch_cos_sims)\n",
    "\n",
    "    # Aggregate results\n",
    "    num_steps = len(timesteps)\n",
    "    aggregated_cos_sims = []\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        step_sims = []\n",
    "        for batch_idx in range(len(all_cosine_sims)):\n",
    "            step_sims.extend(all_cosine_sims[batch_idx][step])\n",
    "        aggregated_cos_sims.append(np.array(step_sims))\n",
    "\n",
    "    # Calculate statistics for each timestep\n",
    "    mean_cos_sims = np.array([sims.mean() for sims in aggregated_cos_sims])\n",
    "    std_cos_sims = np.array([sims.std() for sims in aggregated_cos_sims])\n",
    "    min_cos_sims = np.array([sims.min() for sims in aggregated_cos_sims])\n",
    "    max_cos_sims = np.array([sims.max() for sims in aggregated_cos_sims])\n",
    "\n",
    "    return {\n",
    "        \"timesteps\": timesteps,\n",
    "        \"mean\": mean_cos_sims,\n",
    "        \"std\": std_cos_sims,\n",
    "        \"min\": min_cos_sims,\n",
    "        \"max\": max_cos_sims,\n",
    "        \"all_data\": aggregated_cos_sims\n",
    "    }"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a larger test dataloader for batch analysis\n",
    "batch_size = 16\n",
    "test_dataloader = DataLoader(\n",
    "    test_text_ds,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Analyze multiple batches\n",
    "batch_results = analyze_multiple_batches(unit, test_dataloader, shortcut_size, num_batches=5)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot mean cosine similarity with error bands\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "timesteps = batch_results[\"timesteps\"]\n",
    "mean_cos_sims = batch_results[\"mean\"]\n",
    "std_cos_sims = batch_results[\"std\"]\n",
    "\n",
    "plt.plot(timesteps, mean_cos_sims, 'b-', linewidth=2, label='Mean Cosine Similarity')\n",
    "plt.fill_between(timesteps,\n",
    "                 mean_cos_sims - std_cos_sims,\n",
    "                 mean_cos_sims + std_cos_sims,\n",
    "                 alpha=0.3,\n",
    "                 color='b',\n",
    "                 label='±1 Std Dev')\n",
    "\n",
    "plt.plot(timesteps, batch_results[\"min\"], 'r--', linewidth=1, label='Min Cosine Similarity')\n",
    "plt.plot(timesteps, batch_results[\"max\"], 'g--', linewidth=1, label='Max Cosine Similarity')\n",
    "\n",
    "plt.title('Mean Cosine Similarity Between Predicted and Ground Truth Velocities (Multiple Batches)')\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Cosine Similarity')\n",
    "plt.grid(True)\n",
    "plt.ylim(-1.1, 1.1)  # Cosine similarity range\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Distribution of Cosine Similarities\n",
    "\n",
    "Let's visualize the distribution of cosine similarities at different timesteps."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "timesteps"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Select a few representative timesteps to visualize\n",
    "timesteps = batch_results[\"timesteps\"]\n",
    "num_steps = len(timesteps)\n",
    "\n",
    "# Choose timesteps at different points in the denoising process\n",
    "# Ensure we get unique timesteps by checking the actual timestep values\n",
    "indices_to_plot = []\n",
    "timesteps_to_plot = []\n",
    "\n",
    "# Add first timestep\n",
    "indices_to_plot.append(0)\n",
    "timesteps_to_plot.append(timesteps[0])\n",
    "\n",
    "# Add a few timesteps in between\n",
    "potential_indices = [num_steps // 4, num_steps // 2, 3 * num_steps // 4]\n",
    "for idx in potential_indices:\n",
    "    ts = timesteps[idx]\n",
    "    if ts not in timesteps_to_plot:  # Only add if this timestep isn't already in our list\n",
    "        indices_to_plot.append(idx)\n",
    "        timesteps_to_plot.append(ts)\n",
    "\n",
    "# Add last timestep if it's different from what we already have\n",
    "if timesteps[-1] not in timesteps_to_plot:\n",
    "    indices_to_plot.append(num_steps - 1)\n",
    "    timesteps_to_plot.append(timesteps[-1])\n",
    "\n",
    "# Create histogram plots\n",
    "if len(indices_to_plot) > 0:  # Only create plots if we have timesteps to plot\n",
    "    fig, axes = plt.subplots(len(indices_to_plot), 1, figsize=(12, 4 * len(indices_to_plot)))\n",
    "\n",
    "    # Handle the case where we only have one unique timestep\n",
    "    if len(indices_to_plot) == 1:\n",
    "        axes = [axes]  # Make axes a list with one element\n",
    "\n",
    "    for i, (idx, ts) in enumerate(zip(indices_to_plot, timesteps_to_plot, strict=False)):\n",
    "        ax = axes[i]\n",
    "        cos_sims = batch_results[\"all_data\"][idx]\n",
    "\n",
    "        ax.hist(cos_sims, bins=30, alpha=0.7, color='blue')\n",
    "        ax.axvline(x=cos_sims.mean(), color='r', linestyle='--', linewidth=2, label=f'Mean: {cos_sims.mean():.4f}')\n",
    "\n",
    "        ax.set_title(f'Distribution of Cosine Similarities at Timestep {ts}')\n",
    "        ax.set_xlabel('Cosine Similarity')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_xlim(-1.1, 1.1)\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No unique timesteps found to plot.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've analyzed the cosine similarity between model predictions and ground truth velocities during the denoising process. This analysis provides insights into how well the model is learning to predict the correct direction of change at different timesteps.\n",
    "\n",
    "Key observations:\n",
    "1. The cosine similarity varies across different timesteps, indicating that the model's prediction accuracy changes during the denoising process.\n",
    "2. There is variation in cosine similarity across different examples, suggesting that some examples are easier for the model to predict than others.\n",
    "3. The distribution of cosine similarities at different timesteps provides insights into the model's behavior at different stages of denoising."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Token Probability and L2 Distance Analysis\n",
    "\n",
    "Let's analyze the top-k tokens for each denoising step, showing both probabilities and L2 distances."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load a test batch\n",
    "test_batch = next(iter(test_dataloader))\n",
    "\n",
    "# Set shortcut size for denoising\n",
    "shortcut_size = 1024\n",
    "\n",
    "# Run token tracking for a specific example\n",
    "print(\"Running token tracking for a specific example...\")\n",
    "token_results = denoise_with_token_tracking(unit, test_batch, shortcut_size, top_k=5, example_idx=0)\n",
    "\n",
    "# Get the original input sequence\n",
    "input_ids = test_batch.seqs[0].cpu().numpy()\n",
    "input_mask = test_batch.input_ids_mask[0].cpu().numpy()\n",
    "padding_mask = test_batch.padding_mask[0].cpu().numpy()\n",
    "\n",
    "# Print the input sequence\n",
    "print(\"\\nInput sequence (showing only non-padding tokens):\")\n",
    "tokens = []\n",
    "for i, (token_id, is_padding) in enumerate(zip(input_ids, padding_mask, strict=False)):\n",
    "    if is_padding:\n",
    "        is_input = \"Input\" if input_mask[i] == 0 else \"Target\"\n",
    "        token_text = unit.criterion.flow_matching_criterion.tokenizer.decode([token_id])\n",
    "        tokens.append(f\"{i}: {token_text} ({is_input})\")\n",
    "\n",
    "print(\"\\n\".join(tokens))\n",
    "\n",
    "# Print the positions that contribute to the loss\n",
    "print(\"\\nPositions that contribute to the loss (non-input, non-padding):\")\n",
    "print(token_results[\"loss_positions\"])\n",
    "\n",
    "# Select specific timesteps to visualize\n",
    "timesteps = token_results[\"timesteps\"]\n",
    "num_steps = len(timesteps)\n",
    "\n",
    "# Choose timesteps at different points in the denoising process\n",
    "if num_steps >= 5:\n",
    "    timestep_indices = [0, num_steps // 4, num_steps // 2, 3 * num_steps // 4, num_steps - 1]\n",
    "else:\n",
    "    timestep_indices = list(range(num_steps))\n",
    "\n",
    "# Visualize the selected timesteps\n",
    "visualize_top_k_tokens(token_results, timestep_indices=timestep_indices, figsize=(15, 4 * len(timestep_indices)))\n",
    "\n",
    "# Print the top tokens at the final timestep\n",
    "print(\"\\nTop tokens at the final timestep:\")\n",
    "final_timestep = token_results[\"timesteps\"][-1]\n",
    "final_token_texts = token_results[\"token_texts\"][-1]\n",
    "final_token_probs = token_results[\"token_probs\"][-1]\n",
    "\n",
    "for pos_idx, pos in enumerate(token_results[\"loss_positions\"]):\n",
    "    print(f\"Position {pos}:\")\n",
    "    for token_idx, (token, prob) in enumerate(zip(final_token_texts[pos_idx], final_token_probs[pos_idx], strict=False)):\n",
    "        print(f\"  {token_idx+1}. {token} (prob: {prob:.4f})\")\n",
    "    print()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "timesteps = results[\"timesteps\"]\n",
    "cosine_similarities = results[\"cosine_similarities\"]\n",
    "predicted_velocity_norms = np.array(results[\"predicted_velocity_norms\"])\n",
    "ground_truth_velocity_norms = np.array(results[\"ground_truth_velocity_norms\"])\n",
    "norm_diff = predicted_velocity_norms - ground_truth_velocity_norms\n",
    "\n",
    "# Plot for each example\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for i in range(cosine_similarities[0].shape[0]):\n",
    "    example_cos_sims = [cs[i].cpu().item() for cs in cosine_similarities]\n",
    "    plt.plot(timesteps, example_cos_sims, marker='.', linestyle='-', label=f'CosSim Example {i+1}')\n",
    "\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Cosine Similarity')\n",
    "plt.ylim(-1.1, 1.1)\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot norm difference on a secondary y-axis\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(timesteps, norm_diff, color='black', marker='x', linestyle='--', label='Norm Difference (Pred - GT)')\n",
    "ax2.set_ylabel('Norm Difference')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.title('Cosine Similarity and Velocity Norm Difference During Denoising')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "\n",
    "input1 = torch.randn(100, 128)\n",
    "input2 = torch.randn(100, 128)\n",
    "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "output = cos(input1, input2)\n",
    "output"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "output.shape"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
