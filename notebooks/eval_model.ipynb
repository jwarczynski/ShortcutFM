{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45407af45e95a6d9",
   "metadata": {},
   "source": [
    "# Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e7ac8539aa4cf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:11:19.496511Z",
     "start_time": "2025-05-22T14:11:07.509439Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "# Add parent directory to path to import shortcutfm modules\n",
    "sys.path.append('..')\n",
    "from shortcutfm.analysis.denoising import denoise_with_velocity_tracking\n",
    "from shortcutfm.batch import collate\n",
    "from shortcutfm.config import TrainingConfig\n",
    "from shortcutfm.text_datasets import TextDataset\n",
    "from shortcutfm.train.pl.trainer_factory import (\n",
    "    create_criterion,\n",
    "    load_unit_from_checkpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcab2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "# Add parent directory to path to import shortcutfm modules\n",
    "sys.path.append('..')\n",
    "from shortcutfm.analysis.denoising import denoise_with_velocity_tracking\n",
    "from shortcutfm.batch import collate\n",
    "from shortcutfm.config import TrainingConfig\n",
    "from shortcutfm.text_datasets import TextDataset\n",
    "from shortcutfm.train.pl.trainer_factory import (\n",
    "    create_criterion,\n",
    "    load_unit_from_checkpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "552ae5e1b76449f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:11:39.652239Z",
     "start_time": "2025-05-22T14:11:39.629498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training config from ..\\checkpoints\\run_q2qzjeso\\training_config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Set the checkpoint directory\n",
    "checkpoint_dir = Path(\"../checkpoints/run_30me1xfs\")\n",
    "checkpoint_path = checkpoint_dir / \"last-v1.ckpt\"\n",
    "training_config_path = checkpoint_dir / \"training_config.yaml\"\n",
    "\n",
    "checkpoint_dir = Path(\"../checkpoints/run_q2qzjeso\")\n",
    "checkpoint_path = checkpoint_dir / \"epoch=190-step=27100.ckpt\"\n",
    "training_config_path = checkpoint_dir / \"training_config.yaml\"\n",
    "\n",
    "# checkpoint_dir = Path(\"../checkpoints/run_baseline\")\n",
    "# checkpoint_path = checkpoint_dir / \"last.ckpt\"\n",
    "# training_config_path = checkpoint_dir / \"training_config.yaml\"\n",
    "\n",
    "# Load training configuration\n",
    "with open(training_config_path) as f:\n",
    "    yaml_cfg = OmegaConf.load(f)\n",
    "\n",
    "training_config = TrainingConfig(**OmegaConf.to_container(yaml_cfg, resolve=True)) # type: ignore\n",
    "print(f\"Loaded training config from {training_config_path}\")\n",
    "\n",
    "def create_test_dataloader(split: str = \"test\", batch_size: int = 128) -> DataLoader:\n",
    "    \"\"\"Create test dataloader from config.\"\"\"\n",
    "    test_data_path = Path().cwd().parent / \"datasets\" / \"tokenized\" / \"bert-base-uncased\" / \"QQP-Official\"\n",
    "    test_data_path = test_data_path / split\n",
    "                \n",
    "    test_ds = Dataset.load_from_disk(test_data_path)\n",
    "    test_text_ds = TextDataset(test_ds)\n",
    "\n",
    "    return DataLoader(\n",
    "        test_text_ds,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        persistent_workers=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03a83577d2a1d05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:11:57.680102Z",
     "start_time": "2025-05-22T14:11:48.993540Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shortcutfm.train.pl.train_unit import TrainModule\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "pl.seed_everything(training_config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "804cb4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shortcutfm.criteria import CompositeCriterion\n",
    "from shortcutfm.train.pl.train_unit import TrainModule\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "def load_unit_from_checkpoint(\n",
    "    criterion: Union[CompositeCriterion],\n",
    "    checkpoint_path: Union[Path, str],\n",
    "    training_config: TrainingConfig,\n",
    "    denoising_step_size: int = None,\n",
    "    prediction_shortcut_size: int = None,\n",
    ") -> TrainModule:\n",
    "    \"\"\"Load and configure training unit from checkpoint with key remapping.\n",
    "\n",
    "    :param criterion: Criterion instance to use for training\n",
    "    :type criterion: CompositeCriterion | FlowNllCriterion\n",
    "    :param checkpoint_path: Path to the checkpoint file\n",
    "    :type checkpoint_path: Path | str\n",
    "    :param training_config: Training configuration containing optimizer settings\n",
    "    :type training_config: TrainingConfig\n",
    "    :param denoising_step_size: Number of denoising steps (optional)\n",
    "    :type denoising_step_size: int | None\n",
    "    :param prediction_shortcut_size: Size of prediction shortcut (optional)\n",
    "    :type prediction_shortcut_size: int | None\n",
    "    :return: Configured training unit loaded from checkpoint\n",
    "    :rtype: TrainModule\n",
    "    \"\"\"\n",
    "    denoising_step_size = denoising_step_size or training_config.denoising_step_size\n",
    "    prediction_shortcut_size = prediction_shortcut_size or training_config.prediction_shortcut_size\n",
    "\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(str(checkpoint_path), map_location=torch.device('cpu'), weights_only=False)\n",
    "\n",
    "    # Get the state dictionary from the checkpoint\n",
    "    state_dict = checkpoint.get('state_dict', checkpoint)\n",
    "\n",
    "    new_state_dict = {}\n",
    "    for key, value in state_dict.items():\n",
    "        # Remap keys: replace 'nll' with 'consistency_criterion' or 'embedding_criterion'\n",
    "        if 'criterion.nll' in key or 'criterion.flow_matching_criterion' in key:\n",
    "            # Determine which criterion to map to based on context or configuration\n",
    "            # For simplicity, we assume mapping to 'consistency_criterion' for some keys\n",
    "            # and 'embedding_criterion' for others. Adjust this logic as needed.\n",
    "            new_key = key.replace('criterion.nll', 'criterion.embedding_criterion')\n",
    "            new_key = key.replace('criterion.flow_matching_criterion', 'criterion.embedding_criterion')\n",
    "            # Alternatively, for embedding_criterion, you might need a condition\n",
    "            # new_key = key.replace('criterion.nll', 'criterion.embedding_criterion')\n",
    "            new_state_dict[new_key] = value\n",
    "        else:\n",
    "            new_state_dict[key] = value\n",
    "\n",
    "    # Initialize the TrainModule\n",
    "    unit = TrainModule(\n",
    "        criterion=criterion,\n",
    "        optimizer_config=training_config.optimizer.scheduler,\n",
    "        prediction_shortcut_size=prediction_shortcut_size,\n",
    "        denoising_step_size=denoising_step_size,\n",
    "    )\n",
    "\n",
    "    # Load the remapped state dictionary into the model\n",
    "    try:\n",
    "        unit.load_state_dict(new_state_dict, strict=False)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error loading state dict: {e}\")\n",
    "        raise\n",
    "\n",
    "    return unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485ec1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word emebedding reuires grad: False\n",
      "lm head requires grad: True\n",
      "Loaded model from ..\\checkpoints\\run_q2qzjeso\\epoch=190-step=27100.ckpt\n",
      "UNIT lodaed succesfully\n"
     ]
    }
   ],
   "source": [
    "# Create criterion and load model from checkpoint\n",
    "from itertools import islice\n",
    "\n",
    "denoising_step_size = 128\n",
    "shortcut_size = 128\n",
    "\n",
    "criterion = create_criterion(training_config)\n",
    "unit: TrainModule = load_unit_from_checkpoint(\n",
    "        criterion,\n",
    "        checkpoint_path,\n",
    "        training_config,\n",
    "        denoising_step_size,\n",
    "        shortcut_size,\n",
    "    )\n",
    "print(f\"Loaded model from {checkpoint_path}\")\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "unit.eval()\n",
    "print(\"UNIT lodaed succesfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9788d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_test_batches = 16\n",
    "\n",
    "# Load the dataset\n",
    "split = \"valid\"\n",
    "test_dataloader = create_test_dataloader(split, batch_size=8)\n",
    "if limit_test_batches is not None:\n",
    "    test_dataloader = islice(test_dataloader, limit_test_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "993736b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = unit.criterion.flow_matching_criterion.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f1e3685724d2ed9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:28:56.521639Z",
     "start_time": "2025-05-22T14:28:56.515640Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1302b1a77199ee66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e2ae0e5ce74fdcb2dae50a49ce7722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "denoising_step_size = 2048\n",
    "shortcut_size = 2048\n",
    "\n",
    "total_batches = len(test_dataloader) if not isinstance(test_dataloader, islice) else limit_test_batches\n",
    "for batch_idx, test_batch in enumerate(tqdm(test_dataloader, desc=\"Evaluating\", total=total_batches)):\n",
    "    test_batch = test_batch.to(unit.device)\n",
    "    predicted_ids: Tensor = unit.criterion.denoise(\n",
    "        test_batch, \n",
    "        shortcut_size, \n",
    "        step_size=denoising_step_size,\n",
    "        probe_every_step=False,\n",
    "        return_logits=False,\n",
    "        use_ground_truth_embeddings=True,\n",
    "    ) # type: ignore\n",
    "    \n",
    "    inputs.append(test_batch.seqs.detach().cpu())\n",
    "    predictions.append(predicted_ids.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a6311b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = torch.cat(inputs, dim=0)\n",
    "all_predictions = torch.cat(predictions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ae0e002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7932ecd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: {'bleu': 0.9937063061227939, 'precisions': [0.9964002879769619, 0.9944488501189532, 0.9929390997352162, 0.991044776119403], 'brevity_penalty': 1.0, 'length_ratio': 1.0021645021645023, 'translation_length': 1389, 'reference_length': 1386}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "from scripts.evaluate_seq import process_prediction, process_sequence\n",
    "\n",
    "\n",
    "input_texts = [tokenizer.decode(seq, skip_special_tokens=False) for seq in all_inputs]\n",
    "sources, references = zip(*[process_sequence(text, tokenizer) for text in input_texts], strict=False)\n",
    "references = list(references)  # Convert tuple to list\n",
    "\n",
    "\n",
    "# Process predictions (take last step predictions)\n",
    "pred_texts = [tokenizer.decode(seq, skip_special_tokens=False) for seq in all_predictions]\n",
    "hypotheses = [process_prediction(text, tokenizer) for text in pred_texts]\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {}\n",
    "\n",
    "# BLEU score\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "bleu_score = bleu.compute(predictions=hypotheses, references=[[ref] for ref in references])\n",
    "metrics[\"bleu\"] = bleu_score\n",
    "print(f\"BLEU score: {bleu_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0baa7ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Source: why is tokyo so big?\n",
      "Reference: why has tokyo grown to be a such large city?\n",
      "Hypothesis: why has tokyo grown to be a such large city?\n",
      "******************************\n",
      "\n",
      "\n",
      "******************************\n",
      "Source: why does he want to have sex with me not her?\n",
      "Reference: why did he chose me to have sex with?\n",
      "Hypothesis: why did he chose me to have sex with?\n",
      "******************************\n",
      "\n",
      "\n",
      "******************************\n",
      "Source: what could be the effect of gst bill on indian economy?\n",
      "Reference: how can the gst bill, passed by the rajyasabha yesterday, boost the indian economy?\n",
      "Hypothesis: how can the gst bill, passed by the rajyasabha yesterday, boost the indian economy?\n",
      "******************************\n",
      "\n",
      "\n",
      "******************************\n",
      "Source: how will the ban on 500 and 1000 rupee notes bring out the black money of the big shots who have lots of it in the swiss bank in a different currency?\n",
      "Reference: how is demonetizing the rs 500 and 1000 currencies affects indian economy? how this affect the black money in swiss accounts?\n",
      "Hypothesis: how is demonetizing the rs 500 and 1000 currencies affects indian economy? how this affect the black money in swiss accounts?\n",
      "******************************\n",
      "\n",
      "\n",
      "******************************\n",
      "Source: have the ancient mayans been scientifically tested?\n",
      "Reference: has ancient mesopotamia been scientifically tested?\n",
      "Hypothesis: has ancient mesopotamia been scientifically tested?\n",
      "******************************\n",
      "\n",
      "\n",
      "******************************\n",
      "Source: what do you think the cutoff of kvpy 2016 sa would be?\n",
      "Reference: what do you think about the kvpy 2016 paper?\n",
      "Hypothesis: what do you think about the kvpy 2016 paper?\n",
      "******************************\n",
      "\n",
      "\n",
      "******************************\n",
      "Source: where can you get a scooby doo dog coll?\n",
      "Reference: can you get a scooby doo collar for your dog?\n",
      "Hypothesis: can you get a scooby doo collar for your dog?\n",
      "******************************\n",
      "\n",
      "\n",
      "******************************\n",
      "Source: when / how did you realize were not straight?\n",
      "Reference: when / how did you realize you were gay / bisexual? were you in denial?\n",
      "Hypothesis: when / how did you realize you were gay / bisexual? were you in denial?\n",
      "******************************\n",
      "\n",
      "\n",
      "******************************\n",
      "Source: what is a list of the subfields of psychology and what are their distinctions?\n",
      "Reference: what are the subfields of psychology?\n",
      "Hypothesis: what are the sub fields of psychology?\n",
      "******************************\n",
      "\n",
      "\n",
      "******************************\n",
      "Source: what colors are in the mexican flag and what does the flag mean?\n",
      "Reference: what is the significance of the colors in the mexican flag?\n",
      "Hypothesis: what is the significance of the colors in the mexican flag?\n",
      "******************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for src, ref, hyp in islice(zip(sources, references, hypotheses, strict=False), 10):\n",
    "    print(\"*\" * 30)\n",
    "    print(f\"Source: {src}\")\n",
    "    print(f\"Reference: {ref}\")\n",
    "    print(f\"Hypothesis: {hyp}\")\n",
    "    print(\"*\" * 30)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05076f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
