# QQP Training Configuration
# Extends default.yaml with QQP-specific settings

dry_run: false
use_exca: true

infra:
  cluster: "slurm"
  folder: "jobs"
  timeout_min: 180
  mode: "force"
  slurm_partition: "hgx"
  gpus_per_node: 1
  tasks_per_node: 1
  cpus_per_task: 16
  slurm_use_srun: true
  slurm_additional_parameters:
    nodelist: "hgx1"


# Data paths
training_data_path: "datasets/tokenized/bert-base-uncased/QQP-Official/train"
validation_data_path: "datasets/tokenized/bert-base-uncased/QQP-Official/valid"
check_val_every_n_epoch: 2000
val_interval: null

denoising_step_size: 32  # Step size for denoising process
num_val_batches_to_log: 1  # Number of validation batches to log predictions for
num_timestep_bins: 4
prediction_shortcut_size: 32
log_train_predictions_every_n_epochs: 100  # Number of epochs between train prediction logging
log_train_predictions_from_n_epochs: 100  # Number of epochs between train prediction logging

limit_train_batches: null
limit_val_batches: 2
overfit_batches: 2

max_steps: 2000
gradient_clipping: null
reduce_fn: "mean"

batch_size: 8
accumulate_grad_batches: 2

architecture: "transformer"

seed: 44

normalize_flow_matching_loss: false

flow_matching_loss_weight: 1.0
consistency_loss_weight: 1.0
nll_loss_weight: 1.0
isotropy_loss_weight: 0.0

self_consistency_ratio: 0.0
model:
  init_pretrained: bert
  config_name: bert-base-uncased
  use_pretrained_weights: false
  freeze_word_embedding: false
  vocab_size: 30522
  word_embedding_std: 1.0
  input_dims: 128
  output_dims: 128
  sc_rate: 0.0
  parametrization: "x0"
  stacked_embeddings: false
  hidden_t_dim: 128
  hidden_shortcut_dim: null
  projection_activation: "gelu"
  normalize_word_embedding: false

# Optimizer configuration
optimizer:
  scheduler:
    lr: 3e-4
    type: "linear"
    start_factor: 1.0
    end_factor: 0.01
    total_steps: 5000

#ema: null

# WandB configuration
wandb:
  project_name: "test_v2"
#  run_name: "ffn_inside_criterion"
  enabled: true

# Checkpoint configuration
checkpoint:
  save_folder: "checkpoints/qqp"