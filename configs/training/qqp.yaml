# QQP Training Configuration
# Extends default.yaml with QQP-specific settings

dry_run: false

infra:
  cluster: "slurm"
  folder: "jobs"
  job_name: "exca"
  mode: force
  slurm_partition: "hgx"
  gpus_per_node: 2
  tasks_per_node: 2
  slurm_use_srun: true
  slurm_additional_parameters:
    nodelist: "hgx2"


# Data paths
training_data_path: "datasets/tokenized/QQP-Official/train"
validation_data_path: "datasets/tokenized/QQP-Official/valid"
check_val_every_n_epoch: 5
val_interval: null

max_steps: 50000
gradient_clipping: 2.0


batch_size: 256
accumulate_grad_batches: 8


# Optimizer configuration
optimizer:
  scheduler:
    type: "myle"
    lr: 3e-4
    weight_decay: 0.1
    warmup_steps: 100
    start_lr: 1e-7

self_consistency_ratio: 0.0
model:
  sc_rate: 0.5

# WandB configuration
wandb:
  project_name: "shortcutFM"
  run_name: "sc-0.5_shortcut-0.0-qqp"
  enabled: true

# Checkpoint configuration
checkpoint:
  save_folder: "checkpoints/qqp/sc-0.5_shortcut-0.0-qqp"