# Runtime settings
dry_run: true
use_composer: false

# Data configuration
training_data_path: null  # Required: Set in specific dataset config
validation_data_path: null   # Required: Set in specific dataset config
test_data_path: null        # Required: Set in specific dataset config

# Training process settings
log_interval: 1
val_interval: 5000
self_consistency_ratio: 0.25
max_steps: 10
warmup_steps: 100
start_lr: 1e-7
lr: 3e-4
weight_decay: 0.1
gradient_clipping: 2.0

batch_size: 16
accumulate_grad_batches: 8

deterministic: true
seed: 44

limit_train_batches: 2
limit_val_batches: 2

# Model configuration
model_config:
  input_dims: 768
  hidden_size: 768
  output_dims: 768
  hidden_t_dim: 128
  diffusion_steps: 2048
  min_shortcut_size: 32
  dropout: 0.1
  config_name: "bert-base-uncased"
  vocab_size: 30522
  init_pretrained: "no"
  logits_mode: 1
  sc_rate: 0.5
  predict_t: false
  max_position_embeddings: null

# WandB configuration
wandb:
  project_name: "test"
  run_name: "SFM_v0"
  resume: "allow"
  enabled: true

# Checkpoint configuration
checkpoint:
  save_folder: "checkpoints/test"
  save_interval: 100
  num_to_keep: -1
  overwrite: false
  save_last: true
  save_top_k: -1
  monitor: null
  mode: "min"

# EMA configuration
ema:
  smoothing: 0.99
  half_life: null
  update_interval: 1

